{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c95b1b71",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'raw_training_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n\u001b[1;32m      3\u001b[0m random\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;241m25\u001b[39m) \u001b[38;5;66;03m# set a random seed\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m copy_raw_training_data \u001b[38;5;241m=\u001b[39m \u001b[43mraw_training_data\u001b[49m\u001b[38;5;241m.\u001b[39mcopy()  \u001b[38;5;66;03m# copy the raw training data\u001b[39;00m\n\u001b[1;32m      5\u001b[0m shape \u001b[38;5;241m=\u001b[39m copy_raw_training_data\u001b[38;5;241m.\u001b[39mshape  \u001b[38;5;66;03m# store dimension of raw training data\u001b[39;00m\n\u001b[1;32m      6\u001b[0m num_entries \u001b[38;5;241m=\u001b[39m shape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m (shape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# store number of entries for all independent variables\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'raw_training_data' is not defined"
     ]
    }
   ],
   "source": [
    "# randomly set 1% of the data to null values\n",
    "\n",
    "import random\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, f1_score\n",
    "\n",
    "random.seed(25) # set a random seed\n",
    "copy_raw_training_data = raw_training_data.copy()  # copy the raw training data\n",
    "shape = copy_raw_training_data.shape  # store dimension of raw training data\n",
    "num_entries = shape[0] * (shape[1] - 1)  # store number of entries for all independent variables\n",
    "num_null = int(num_entries * 0.01)  # make 1% of the data be null entries\n",
    "\n",
    "# randomly select entries and replace them with NaN, excluding the response variable\n",
    "for _ in range(num_null):\n",
    "    rand_row, rand_col = random.randint(0, shape[0] - 1) , random.randint(0, shape[1] - 2) # select a random row and column\n",
    "    copy_raw_training_data.iloc[rand_row, rand_col] = np.nan # store entry as nan\n",
    "    \n",
    "# create a list to store all of the entries which are null: (row, column)\n",
    "null_entries = [(row_index, col_index) \n",
    "                for row_index, row in enumerate(copy_raw_training_data.values) \n",
    "                for col_index, val in enumerate(row) \n",
    "                if pd.isnull(val)]\n",
    "\n",
    "# store all of the entries for the original data set, in the positions of the removed entries\n",
    "actual_entries_store = {} # create dictionary for storing the actual values in the locations that are removed\n",
    "for row, col in null_entries: # loop over every removed entry:\n",
    "    col_name = copy_raw_training_data.columns[col] # store column name of current null entry\n",
    "    if col_name not in actual_entries_store: # check if column name is already in the dictionary\n",
    "        actual_entries_store[col_name] = [] # if not already in dictionary, create empty list\n",
    "    actual_entries_store[col_name].append(raw_training_data.iloc[row, col])# add actual value to the list for correct column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e1663c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputation 1: impute missing values with median for numerical variables and mode for categorical variables\n",
    "\n",
    "imputed1_entries_store = {} # create empty dictionary\n",
    "for col_name in copy_raw_training_data.columns: # loop over each column of the data set \n",
    "    col_data = copy_raw_training_data[col_name] # store data for current column\n",
    "    if col_data.dtype in ['float64', 'int64']: # check if data type of current column is numeric\n",
    "        col_data.fillna(col_data.median(), inplace=True) # impute numerical nulls with median\n",
    "    else:\n",
    "        col_data.fillna(col_data.mode().iloc[0], inplace=True) # impute categorical nulls with mode\n",
    "    imputed1_entries_store[col_name] = [col_data.loc[row] for row, col in null_entries if col_name == copy_raw_training_data.columns[col]] # store the imputed values in the dictionary\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "# test performance of imputation method 1\n",
    "# for numerical variables, measure performance using RMSE.\n",
    "numerical_data = []\n",
    "for col_name, actual_values in actual_entries_store.items():\n",
    "    # change imputed and actual values to be numeric\n",
    "    imputed_values = pd.to_numeric(imputed1_entries_store.get(col_name, []), errors='coerce')\n",
    "    actual_values = pd.to_numeric(actual_values, errors='coerce')\n",
    "    \n",
    "    \n",
    "    #ERROR HERE I NEED TO DEBUG: for some reason there are null values here when there shouldnt be\n",
    "    if not pd.isnull(actual_values).any() and not pd.isnull(imputed_values).any(): # check if both actual and imputed values are available and not containing nulls\n",
    "        numerical_data.append({\"Variable\": col_name, \"RMSE\": mean_squared_error(actual_values, imputed_values, squared=False).round(3)})\n",
    "\n",
    "# Categorical variables\n",
    "categorical_cols = [col for col in copy_raw_training_data.select_dtypes(include=['object']).columns.tolist() if col != 'Status']\n",
    "\n",
    "categorical_data = []\n",
    "for col_name in categorical_cols:\n",
    "    actual_values = actual_entries_store[col_name]\n",
    "    imputed_values = imputed1_entries_store.get(col_name, [])\n",
    "    actual_values = [str(val) for val in actual_values]\n",
    "    imputed_values = [str(val) for val in imputed_values]\n",
    "    accuracy = accuracy_score(actual_values, imputed_values)\n",
    "    f1 = f1_score(actual_values, imputed_values, average='weighted')\n",
    "    categorical_data.append({\"Variable\": col_name, \"Accuracy\": accuracy.round(3), \"F1 Score\": f1.round(3)})\n",
    "\n",
    "# Display the numerical and categorical performance in one cell\n",
    "print(\"Numerical variables performance for imputation 1:\")\n",
    "print(pd.DataFrame(numerical_data).to_string(index=False))\n",
    "\n",
    "print(\"\\nCategorical variables performance for imputation 1:\")\n",
    "print(pd.DataFrame(categorical_data).to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
