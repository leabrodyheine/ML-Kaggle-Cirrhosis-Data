{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95b1b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, f1_score\n",
    "\n",
    "random.seed(25) # set a random seed\n",
    "copy_raw_training_data = raw_training_data.copy()  # copy the raw training data\n",
    "shape = copy_raw_training_data.shape  # store dimension of raw training data\n",
    "num_entries = shape[0] * (shape[1] - 1)  # store number of entries for all independent variables\n",
    "num_null = int(num_entries * 0.01)  # make 1% of the data be null entries\n",
    "\n",
    "# randomly select entries and replace them with NaN, excluding the response variable\n",
    "for _ in range(num_null):\n",
    "    rand_row, rand_col = random.randint(0, shape[0] - 1) , random.randint(0, shape[1] - 2) # select a random row and column\n",
    "    copy_raw_training_data.iloc[rand_row, rand_col] = np.nan # store entry as nan\n",
    "    \n",
    "# create a list to store all of the entries which are null: (row, column)\n",
    "null_entries = [(row_index, col_index) \n",
    "                for row_index, row in enumerate(copy_raw_training_data.values) \n",
    "                for col_index, val in enumerate(row) \n",
    "                if pd.isnull(val)]\n",
    "\n",
    "# store all of the entries for the original data set, in the positions of the removed entries\n",
    "actual_entries_store = {} # create dictionary for storing the actual values in the locations that are removed\n",
    "for row, col in null_entries: # loop over every removed entry:\n",
    "    col_name = copy_raw_training_data.columns[col] # store column name of current null entry\n",
    "    if col_name not in actual_entries_store: # check if column name is already in the dictionary\n",
    "        actual_entries_store[col_name] = [] # if not already in dictionary, create empty list\n",
    "    actual_entries_store[col_name].append(raw_training_data.iloc[row, col])# add actual value to the list for correct column\n",
    "    \n",
    "# store the names of all categorical and numerical columns (excluding the response variable)\n",
    "categorical_cols = [col for col in copy_raw_training_data.select_dtypes(include=['object']).columns.tolist() if col != 'Status']\n",
    "num_cols = [x for x in copy_raw_training_data.columns.drop(['Status']) if x not in categorical_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e1663c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputation 1: impute missing values with median for numerical variables and mode for categorical variables\n",
    "\n",
    "imputed1_entries_store = {} # create empty dictionary\n",
    "for col_name in copy_raw_training_data.columns.drop(['Status']): # loop over each column of the data set \n",
    "    col_data = copy_raw_training_data[col_name] # store data for current column\n",
    "    if col_data.dtype in ['float64', 'int64']: # check if data type of current column is numeric\n",
    "        col_data.fillna(col_data.median(), inplace=True) # impute numerical nulls with median\n",
    "    else:\n",
    "        col_data.fillna(col_data.mode().iloc[0], inplace=True) # impute categorical nulls with mode\n",
    "    imputed1_entries_store[col_name] = [col_data.loc[row] for row, col in null_entries if col_name == copy_raw_training_data.columns[col]] # store the imputed values in the dictionary\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "# test performance of imputation method 1\n",
    "# for numerical variables, measure performance using RMSE.\n",
    "numerical_data = []\n",
    "for col_name, actual_vals in actual_entries_store.items(): # loop over all variables and actual values\n",
    "    # change imputed and actual values to be numeric\n",
    "    imputed_vals = pd.to_numeric(imputed1_entries_store.get(col_name, []), errors='coerce')\n",
    "    actual_vals = pd.to_numeric(actual_vals, errors='coerce')\n",
    "    if col_name in num_cols: # if the column is numeric:\n",
    "        numerical_data.append({\"Variable\": col_name, \"RMSE\": mean_squared_error(actual_vals, imputed_vals, squared=False).round(3)}) # add the column name and its RMSE\n",
    "\n",
    "# for categorical variables, measure performance using accuracy and F1 score.\n",
    "categorical_data = []\n",
    "for col_name in categorical_cols: # loop over all categorical variables\n",
    "    # change imputed and actual values to be a string\n",
    "    imputed_vals = [str(val) for val in imputed1_entries_store.get(col_name, [])]\n",
    "    actual_vals = [str(val) for val in actual_entries_store[col_name]]\n",
    "    accuracy = accuracy_score(actual_vals, imputed_vals) # calculate accuracy score\n",
    "    f1 = f1_score(actual_vals, imputed_vals, average='weighted') # calculate F1 score\n",
    "    categorical_data.append({\"Variable\": col_name, \"Accuracy\": accuracy.round(3), \"F1 Score\": f1.round(3)}) # add the column name and its accuracy and F1 score\n",
    "#---------------------------------------------------------------------------------------------------------------------------\n",
    "# return the performance metrics\n",
    "print(\"Numerical variables performance for imputation 1:\")\n",
    "print(pd.DataFrame(numerical_data).to_string(index=False))\n",
    "print(\"\\nCategorical variables performance for imputation 1:\")\n",
    "print(pd.DataFrame(categorical_data).to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
