{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0ae2d441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[33mWARNING: Value for scheme.platlib does not match. Please report this to <https://github.com/pypa/pip/issues/10151>\n",
      "distutils: /home/trf1/.local/lib/python3.9/site-packages\n",
      "sysconfig: /home/trf1/.local/lib64/python3.9/site-packages\u001b[0m\n",
      "\u001b[33mWARNING: Additional context:\n",
      "user = True\n",
      "home = None\n",
      "root = None\n",
      "prefix = None\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# use pip to install all the libraries we need\n",
    "import sys\n",
    "!{sys.executable} -m pip install numpy pandas matplotlib scikit-learn seaborn | grep -v 'already satisfied'\n",
    "\n",
    "# import necessary packages\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import random\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "warnings.filterwarnings('ignore') # remove warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8896b025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data, dropping the ID column, as this is duplicated by pandas\n",
    "raw_training_data = pd.read_csv(r\"train.csv\").drop(columns=[\"id\"])\n",
    "raw_test_data = pd.read_csv(r\"test.csv\").drop(columns=[\"id\"])\n",
    "\n",
    "copy_raw_training_data = raw_training_data.copy()  # copy the raw training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c0de85fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_copy = copy_raw_training_data.drop(labels=['Status'], axis=1)\n",
    "Y_copy = copy_raw_training_data[\"Status\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f2777aee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N_Days              int64\n",
       "Drug             category\n",
       "Age                 int64\n",
       "Sex              category\n",
       "Ascites          category\n",
       "Hepatomegaly     category\n",
       "Spiders          category\n",
       "Edema            category\n",
       "Bilirubin         float64\n",
       "Cholesterol       float64\n",
       "Albumin           float64\n",
       "Copper            float64\n",
       "Alk_Phos          float64\n",
       "SGOT              float64\n",
       "Tryglicerides     float64\n",
       "Platelets         float64\n",
       "Prothrombin       float64\n",
       "Stage             float64\n",
       "Status           category\n",
       "dtype: object"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert all non-numerical columns into categorical data\n",
    "non_numeric_columns = copy_raw_training_data.select_dtypes(exclude=['number']).columns\n",
    "copy_raw_training_data[non_numeric_columns] = copy_raw_training_data[non_numeric_columns].astype('category')\n",
    "\n",
    "copy_raw_training_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "363acc8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.3</td>\n",
       "      <td>316.0</td>\n",
       "      <td>3.35</td>\n",
       "      <td>172.0</td>\n",
       "      <td>1601.0</td>\n",
       "      <td>179.80</td>\n",
       "      <td>63.0</td>\n",
       "      <td>394.0</td>\n",
       "      <td>9.7</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>364.0</td>\n",
       "      <td>3.54</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>134.85</td>\n",
       "      <td>88.0</td>\n",
       "      <td>361.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.3</td>\n",
       "      <td>299.0</td>\n",
       "      <td>3.55</td>\n",
       "      <td>131.0</td>\n",
       "      <td>1029.0</td>\n",
       "      <td>119.35</td>\n",
       "      <td>50.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>11.7</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>256.0</td>\n",
       "      <td>3.50</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1653.0</td>\n",
       "      <td>71.30</td>\n",
       "      <td>96.0</td>\n",
       "      <td>269.0</td>\n",
       "      <td>10.7</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.1</td>\n",
       "      <td>346.0</td>\n",
       "      <td>3.65</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1181.0</td>\n",
       "      <td>125.55</td>\n",
       "      <td>96.0</td>\n",
       "      <td>298.0</td>\n",
       "      <td>10.6</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7900</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>309.0</td>\n",
       "      <td>3.56</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1629.0</td>\n",
       "      <td>79.05</td>\n",
       "      <td>224.0</td>\n",
       "      <td>344.0</td>\n",
       "      <td>9.9</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7901</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>260.0</td>\n",
       "      <td>3.43</td>\n",
       "      <td>62.0</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>142.00</td>\n",
       "      <td>78.0</td>\n",
       "      <td>277.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7902</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>3.19</td>\n",
       "      <td>51.0</td>\n",
       "      <td>933.0</td>\n",
       "      <td>69.75</td>\n",
       "      <td>62.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>12.7</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7903</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7</td>\n",
       "      <td>248.0</td>\n",
       "      <td>2.75</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1003.0</td>\n",
       "      <td>57.35</td>\n",
       "      <td>118.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>10.6</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7904</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7</td>\n",
       "      <td>256.0</td>\n",
       "      <td>3.23</td>\n",
       "      <td>22.0</td>\n",
       "      <td>645.0</td>\n",
       "      <td>74.40</td>\n",
       "      <td>85.0</td>\n",
       "      <td>336.0</td>\n",
       "      <td>10.3</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7905 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1    2    3    4    5    6    7    8    9   ...   15     16    17  \\\n",
       "0     1.0  0.0  0.0  1.0  1.0  0.0  1.0  0.0  1.0  0.0  ...  2.3  316.0  3.35   \n",
       "1     0.0  1.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  ...  0.9  364.0  3.54   \n",
       "2     0.0  1.0  1.0  0.0  1.0  0.0  0.0  1.0  0.0  1.0  ...  3.3  299.0  3.55   \n",
       "3     0.0  1.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  ...  0.6  256.0  3.50   \n",
       "4     0.0  1.0  1.0  0.0  1.0  0.0  0.0  1.0  1.0  0.0  ...  1.1  346.0  3.65   \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...    ...   ...   \n",
       "7900  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  ...  0.8  309.0  3.56   \n",
       "7901  0.0  1.0  1.0  0.0  1.0  0.0  0.0  1.0  1.0  0.0  ...  0.9  260.0  3.43   \n",
       "7902  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  0.0  1.0  ...  2.0  225.0  3.19   \n",
       "7903  1.0  0.0  0.0  1.0  1.0  0.0  0.0  1.0  1.0  0.0  ...  0.7  248.0  2.75   \n",
       "7904  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  ...  0.7  256.0  3.23   \n",
       "\n",
       "         18      19      20     21     22    23   24  \n",
       "0     172.0  1601.0  179.80   63.0  394.0   9.7  3.0  \n",
       "1      63.0  1440.0  134.85   88.0  361.0  11.0  3.0  \n",
       "2     131.0  1029.0  119.35   50.0  199.0  11.7  4.0  \n",
       "3      58.0  1653.0   71.30   96.0  269.0  10.7  3.0  \n",
       "4      63.0  1181.0  125.55   96.0  298.0  10.6  4.0  \n",
       "...     ...     ...     ...    ...    ...   ...  ...  \n",
       "7900   38.0  1629.0   79.05  224.0  344.0   9.9  2.0  \n",
       "7901   62.0  1440.0  142.00   78.0  277.0  10.0  4.0  \n",
       "7902   51.0   933.0   69.75   62.0  200.0  12.7  2.0  \n",
       "7903   32.0  1003.0   57.35  118.0  221.0  10.6  4.0  \n",
       "7904   22.0   645.0   74.40   85.0  336.0  10.3  3.0  \n",
       "\n",
       "[7905 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "categorical_attributes = [\"Drug\", \"Sex\", \"Ascites\", \"Hepatomegaly\", \"Spiders\", \"Edema\"]\n",
    "\n",
    "onehot = ColumnTransformer([\n",
    "        (\"One_hot_encoder\", OneHotEncoder(), categorical_attributes)], \n",
    "        remainder='passthrough')\n",
    "\n",
    "X_copy_onehot = pd.DataFrame(onehot.fit_transform(X_copy))\n",
    "\n",
    "display(X_copy_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f630a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create random number generator\n",
    "rng = np.random.RandomState(42)\n",
    "\n",
    "def add_missing_values(X_full, Y_full, missing_rate=0.75):\n",
    "    \"\"\"\n",
    "    Takes a dataframe and adds in some missing values.\n",
    "\n",
    "    Parameters:\n",
    "    - X_full: a dataframe containing all columns with independent variables\n",
    "    - Y_full: a dataframe containing the response variable column only\n",
    "    - missing_rate: an integer between 0 and 1 which specifies how many lines should have missing values\n",
    "\n",
    "    Returns:\n",
    "    - X_missing: the dataframe X_full but with some missing values\n",
    "    - Y_missing: an exact copy of Y_full\n",
    "    \"\"\"\n",
    "    n_samples, n_features = X_full.shape\n",
    "\n",
    "    # Add missing values in some of the lines (default is 75%)\n",
    "    n_missing_samples = int(n_samples * missing_rate)\n",
    "\n",
    "    # Create an array the same length as the number of samples with a specified proportion of True values\n",
    "    missing_samples = np.zeros(n_samples, dtype=bool)\n",
    "    missing_samples[:n_missing_samples] = True\n",
    "\n",
    "    # Randomly add missing values to the specified proportion of lines\n",
    "    rng.shuffle(missing_samples)\n",
    "    missing_features = rng.randint(0, n_features, n_missing_samples)\n",
    "    X_missing = X_full.copy()\n",
    "    X_missing.iloc[missing_samples, missing_features] = np.nan\n",
    "    y_missing = Y_full.copy()\n",
    "\n",
    "    return X_missing, y_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95b1b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "random.seed(25) # set a random seed\n",
    "copy_raw_training_data = raw_training_data.copy()  # copy the raw training data\n",
    "shape = copy_raw_training_data.shape  # store dimension of raw training data\n",
    "num_entries = shape[0] * (shape[1] - 1)  # store number of entries for all independent variables\n",
    "num_null = int(num_entries * 0.01)  # make 1% of the data be null entries\n",
    "\n",
    "# randomly select entries and replace them with NaN, excluding the response variable\n",
    "for _ in range(num_null):\n",
    "    rand_row, rand_col = random.randint(0, shape[0] - 1) , random.randint(0, shape[1] - 2) # select a random row and column\n",
    "    copy_raw_training_data.iloc[rand_row, rand_col] = np.nan # store entry as nan\n",
    "    \n",
    "# create a list to store all of the entries which are null: (row, column)\n",
    "null_entries = [(row_index, col_index) \n",
    "                for row_index, row in enumerate(copy_raw_training_data.values) \n",
    "                for col_index, val in enumerate(row) \n",
    "                if pd.isnull(val)]\n",
    "\n",
    "# store all of the entries for the original data set in the positions of the removed entries\n",
    "actual_entries_store = {} # create dictionary for storing the actual values in the locations that are removed\n",
    "for row, col in null_entries: # loop over every removed entry:\n",
    "    col_name = copy_raw_training_data.columns[col] # store column name of current null entry\n",
    "    if col_name not in actual_entries_store: # check if column name is already in the dictionary\n",
    "        actual_entries_store[col_name] = [] # if not already in dictionary, create empty list\n",
    "    actual_entries_store[col_name].append(raw_training_data.iloc[row, col])# add actual value to the list for correct column\n",
    "    \n",
    "# store the names of all categorical and numerical columns (excluding the response variable)\n",
    "categorical_cols = [col for col in copy_raw_training_data.select_dtypes(include=['object']).columns.tolist() if col != 'Status']\n",
    "num_cols = [x for x in copy_raw_training_data.columns.drop(['Status']) if x not in categorical_cols]\n",
    "#--------------------------------------------------------------------------------------------------------------------------\n",
    "# function to calculate performance metrics for numerical variables\n",
    "def calc_num_metrics(actual_entries_store, imputed_entries_store, num_cols):\n",
    "    \"\"\"\n",
    "    Calculates performance metric RMSE for numerical variables for the imputation method\n",
    "    \n",
    "    Parameters:\n",
    "    - actual_entries_store: dictionary containing all entries that were set to NaN, keys are the data frames columns\n",
    "    - imputed_entries_store: dictionary containing all imputed entries, indexed the same as actual_entries_store\n",
    "    - num_cols: list of the numerical columns in the data frame\n",
    "    \n",
    "    Returns:\n",
    "    - Data frame as a string showing the RMSE for the imputation method for each numerical variable\n",
    "    \"\"\"\n",
    "    numerical_data = []\n",
    "    for col_name, actual_vals in actual_entries_store.items(): # loop over all variables and actual values\n",
    "        if col_name in num_cols: # if the current column is numerical:\n",
    "            # change imputed and actual values to be numeric\n",
    "            imputed_vals = pd.to_numeric(imputed_entries_store.get(col_name, []))\n",
    "            actual_vals = pd.to_numeric(actual_vals)\n",
    "            numerical_data.append({\"Variable\": col_name, \"RMSE\": round(mean_squared_error(actual_vals, imputed_vals, squared=False),3)}) # add the column name and its RMSE\n",
    "    return pd.DataFrame(numerical_data).to_string(index=False)\n",
    "\n",
    "# function to calculate performance metrics for categorical variables\n",
    "def calc_categorical_metrics(actual_entries_store, imputed_entries_store, categorical_cols):\n",
    "    \"\"\"\n",
    "    Calculates performance metric accuracy and F1 score for categorical variables for the imputation method\n",
    "    \n",
    "    Parameters:\n",
    "    - actual_entries_store: dictionary containing all entries that were set to NaN, keys are the data frames columns\n",
    "    - imputed_entries_store: dictionary containing all imputed entries, indexed the same as actual_entries_store\n",
    "    - categorical_cols: list of the categorical columns in the data frame\n",
    "    \n",
    "    Returns:\n",
    "    - Data frame as a string showing the accuracy and F1 score for the imputation method for each categorical variable\n",
    "    \"\"\"\n",
    "    categorical_data = []\n",
    "    for col_name in categorical_cols: # loop over all categorical variables\n",
    "        # change imputed and actual values to be a string\n",
    "        imputed_vals = [str(val) for val in imputed_entries_store.get(col_name, [])]\n",
    "        actual_vals = [str(val) for val in actual_entries_store[col_name]]\n",
    "        accuracy = accuracy_score(actual_vals, imputed_vals) # calculate accuracy score\n",
    "        f1 = f1_score(actual_vals, imputed_vals, average='weighted') # calculate F1 score\n",
    "        categorical_data.append({\"Variable\": col_name, \"Accuracy\": round(accuracy,3), \"F1 Score\": round(f1,3)}) # add the column name and its accuracy and F1 score\n",
    "    return pd.DataFrame(categorical_data).to_string(index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e1663c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical variables performance for imputation 1:\n",
      "     Variable     RMSE\n",
      "       N_Days 1178.102\n",
      "    Bilirubin    4.242\n",
      "  Prothrombin    0.796\n",
      "          Age 3782.324\n",
      "  Cholesterol  129.944\n",
      "      Albumin    0.349\n",
      "       Copper   50.941\n",
      "     Alk_Phos 2026.417\n",
      "    Platelets   83.103\n",
      "         SGOT   42.677\n",
      "Tryglicerides   76.562\n",
      "        Stage    0.897\n",
      "\n",
      "Categorical variables performance for imputation 1:\n",
      "    Variable  Accuracy  F1 Score\n",
      "        Drug     0.570     0.414\n",
      "         Sex     0.920     0.882\n",
      "     Ascites     0.949     0.925\n",
      "Hepatomegaly     0.549     0.389\n",
      "     Spiders     0.809     0.723\n",
      "       Edema     0.918     0.878\n"
     ]
    }
   ],
   "source": [
    "# Imputation 1: impute missing values with median for numerical variables and mode for categorical variables\n",
    "\n",
    "imputed1_entries_store = {} # create empty dictionary\n",
    "for col_name in copy_raw_training_data.columns.drop(['Status']): # loop over each column of the data set \n",
    "    col_data = copy_raw_training_data[col_name] # store data for current column\n",
    "    if col_data.dtype in ['float64', 'int64']: # check if data type of current column is numeric\n",
    "        col_data.fillna(col_data.median(), inplace=True) # impute numerical nulls with median\n",
    "    else:\n",
    "        col_data.fillna(col_data.mode().iloc[0], inplace=True) # impute categorical nulls with mode\n",
    "    imputed1_entries_store[col_name] = [col_data.loc[row] for row, col in null_entries if col_name == copy_raw_training_data.columns[col]] # store the imputed values in the dictionary\n",
    "\n",
    "# Display performance metrics\n",
    "print(\"Numerical variables performance for imputation 1:\")\n",
    "print(calc_num_metrics(actual_entries_store, imputed1_entries_store, num_cols))\n",
    "print(\"\\nCategorical variables performance for imputation 1:\")\n",
    "print(calc_categorical_metrics(actual_entries_store, imputed1_entries_store, categorical_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa663cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N_Days           float64\n",
       "Drug              object\n",
       "Age              float64\n",
       "Sex               object\n",
       "Ascites           object\n",
       "Hepatomegaly      object\n",
       "Spiders           object\n",
       "Edema             object\n",
       "Bilirubin        float64\n",
       "Cholesterol      float64\n",
       "Albumin          float64\n",
       "Copper           float64\n",
       "Alk_Phos         float64\n",
       "SGOT             float64\n",
       "Tryglicerides    float64\n",
       "Platelets        float64\n",
       "Prothrombin      float64\n",
       "Stage            float64\n",
       "Status            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "copy_raw_training_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f99360",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Placebo'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_802419/3493669244.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;31m# Imputation 2: impute each missing value with the mean value from k nearest neighbours\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mX_copy_miss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_copy_miss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_missing_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_copy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_copy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmissing_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.75\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             return_tuple = (\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m   1094\u001b[0m                 )\n\u001b[1;32m   1095\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m                 skip_parameter_validation=(\n\u001b[1;32m   1471\u001b[0m                     \u001b[0mprefer_skip_nested_validation\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mglobal_skip_validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1472\u001b[0m                 )\n\u001b[1;32m   1473\u001b[0m             ):\n\u001b[0;32m-> 1474\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/impute/_knn.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mforce_all_finite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mforce_all_finite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"allow-nan\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         X = self._validate_data(\n\u001b[0m\u001b[1;32m    231\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    995\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    997\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 999\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m   1000\u001b[0m                     \u001b[0;34m\"Complex data not supported\\n{}\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m                 ) from complex_warning\n\u001b[1;32m   1002\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/utils/_array_api.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[1;32m    517\u001b[0m         \u001b[0;31m# Use NumPy API to support order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0;31m# At this point array is a NumPy ndarray. We convert it to an array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m         \u001b[0;31m# container that is consistent with the input's namespace.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   2148\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDTypeLike\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2149\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2150\u001b[0;31m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2151\u001b[0m         if (\n\u001b[1;32m   2152\u001b[0m             \u001b[0mastype_is_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2153\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0musing_copy_on_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Placebo'"
     ]
    }
   ],
   "source": [
    "# Imputation 2: impute each missing value with the mean value from k nearest neighbours\n",
    "\n",
    "X_copy_miss, Y_copy_miss = add_missing_values(X_copy, Y_copy, missing_rate=0.75)\n",
    "\n",
    "independent_vars = copy_raw_training_data.drop(labels=['Status'], axis=1)   # ignore the status column\n",
    "numerical = independent_vars.select_dtypes(include=[\"float64\", \"int64\"])    # separate out the numerical data\n",
    "categorical = independent_vars.select_dtypes(exclude=[\"float64\", \"int64\"])\n",
    "\n",
    "imputed2_entries_store = {} # create empty dictionary\n",
    "imputer2 = KNNImputer(n_neighbors=2)    # create a KNN imputer\n",
    "imputer2.fit_transform(X_copy_miss)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
